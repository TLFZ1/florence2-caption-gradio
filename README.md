# 🖼️ Florence-2 批量图片描述生成工具 (Gradio 可视化版)

这是一个基于 [Microsoft Florence-2](https://huggingface.co/microsoft/Florence-2-large) 系列模型的高性能、可视化的批量图片描述（打标）工具。它将复杂的模型推理和文件处理流程封装在了一个友好、易于操作的Web界面中，旨在为训练文生图（Text-to-Image）模型（如Stable Diffusion）提供高质量的训练集标注。

我们从一个基础的命令行脚本出发，通过逐步迭代，最终实现了这个功能全面、性能卓越且具备智能显存管理的可视化工具。

**主界面布局:**

![image](https://github.com/user-attachments/assets/321d79c9-b27a-4154-a4da-7ad3e456dec0)

## ✨ 主要特性

* **可视化操作界面**: 所有参数均可通过Gradio Web UI进行设置，无需修改任何代码。
* **多模型支持**: 支持在多个Florence-2模型（包括基础版、微调版和社区版）之间一键切换。
* **智能显存管理**: 在切换不同模型时，会自动卸载旧模型以释放显存，有效防止因模型叠加导致的显存溢出。
* **断点续传**: 自动跳过输出文件夹中已存在的标签文件，方便在任务中断后继续处理，避免重复工作。
* **高性能数据加载**: 底层使用PyTorch `DataLoader`，可配置多进程加载（`num_workers`）来加速图片预处理。
* **先进的计算加速**: 支持通过`SDPA`和`FlashAttention 2`来加速模型的注意力计算，提升推理速度。
* **丰富的参数配置**: 从路径、模型、精度到生成细节，几乎所有关键参数都可以在界面上进行调整。
* **高级功能开关**: 提供“一键清理旧标签”、“跳过已存在文件”等实用功能。
* **实时进度与日志**: 在界面上实时显示处理进度、状态信息和详细的日志，让漫长的处理过程不再“黑盒”。

## 💿 安装与环境准备

在运行脚本前，请确保您已准备好相应的环境。

**1. 前提条件**
* 已安装 Python 3.8 或更高版本。
* 已安装NVIDIA显卡，并正确配置了CUDA驱动。

**2. 创建虚拟环境 (推荐)**
建议使用`conda`或`venv`创建一个独立的Python虚拟环境，以避免与系统环境或其他项目产生冲突。

```bash
# 使用 conda 创建并激活环境
conda create -n florence2 python=3.10.8
conda activate florence2
```

**3. 安装依赖**
将以下内容保存到一个名为 `requirements.txt` 的文件中，然后运行`pip`命令进行安装。

**`requirements.txt` 文件内容:**
```txt
torch
transformers
gradio
tqdm
Pillow
# 以下为可选的高性能包，建议安装
# flash-attn --no-build-isolation
```

**安装命令:**
```bash
pip install -r requirements.txt
```
* **注意**: `flash-attn` 的安装可能需要较长时间并依赖编译环境。如果安装失败，脚本依然可以通过默认的`sdpa`模式正常运行。

## 🚀 如何使用

1.  **修改默认值 (可选)**:
    直接打开 `.py` 脚本文件，在顶部的“Gradio界面默认值配置区”修改各项参数的默认值。

2.  **运行脚本**:
    在您的终端中，激活虚拟环境，然后运行以下命令：
    ```bash
    python your_script_name.py
    ```
    (请将 `your_script_name.py` 替换为您保存的实际文件名)

3.  **打开浏览器**:
    脚本运行后，终端会显示一个本地网址，通常是 `http://127.0.0.1:7860`。脚本会自动在您的默认浏览器中打开这个地址。

4.  **配置并开始任务**:
    在打开的网页界面中：
    * 设置**输入图片文件夹**和**输出标签文件夹**。
    * 根据需要调整其他模型、性能和生成参数。
    * 点击“**开始批量打标**”按钮，即可开始任务。

## ⚙️ 参数详解

界面上的所有选项都对应着脚本的各项功能：

### 1. 路径设置
* **输入图片文件夹**: 存放您要处理的原始图片的目录。
* **输出标签文件夹**: 保存生成的`.txt`标签文件的目录。
* **模型缓存目录**: 用于下载和存放Hugging Face模型文件的本地路径。

### 2. 模型与精度
* **选择模型**: 从下拉列表中选择要使用的Florence-2模型。
* **计算精度**:
    * `fp32`: 全精度，结果最精确，显存占用最大。
    * `fp16` / `bf16`: 半精度，速度更快，显存占用更低，但可能存在极微小的精度差异。
* **注意力机制实现**: 推荐使用`sdpa`以自动启用最佳加速方案。

### 3. 生成效果设置
* **任务提示词**: 指导模型执行特定任务的指令，如`<MORE_DETAILED_CAPTION>`。
* **最大生成长度**: 限制生成文本的最大Token数量，防止无限生成和控制KV缓存大小。
* **集束搜索宽度 (Num Beams)**: 大于1时启用集束搜索，通常能提升生成质量，但会增加计算量。
* **启用提前停止 (Early Stopping)**: 与`Num Beams`配合使用。勾选后，当所有搜索路径都生成结束符时会提前停止，输出更简洁；不勾选则会进行最详尽的搜索，输出可能更好。

### 4. 运行与功能设置
* **批处理大小 (Batch Size)**: 一次性送入模型处理的图片数量。是影响速度和显存占用的最关键因素。
* **数据加载进程数**: 设置大于0可并行加载数据，提升速度。**但在Gradio中，为确保“强制停止”按钮能立即生效，此值必须设为0**。
* **开始前清理旧标签文件**: 勾选后，在任务开始前，会自动清理输出文件夹中所有`.txt`文件的填充词和换行符。
* **跳过已存在的标签文件**: 勾选后，如果图片已有同名的`.txt`标签文件，则会跳过，实现断点续传。

## ⚠️ 注意事项

* **首次加载**: 第一次选择并运行一个新模型时，程序需要从Hugging Face Hub下载模型文件，可能会花费较长时间，请耐心等待。模型下载后会被缓存，后续加载会非常快。
* **显存管理**: 如果遇到“CUDA out of memory”（爆显存）的错误，首要的解决方案是**降低“批处理大小 (Batch Size)”**。
* **停止按钮**: Gradio的停止按钮机制要求数据加载器在主进程中运行，因此`数据加载进程数`必须设置为`0`，才能确保点击“强制停止”后任务能被立即中断。
